{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab | Data cleaning and wrangling\n",
    "\n",
    "For this lab, we will be using the same dataset we used in the previous labs. We recommend using the same notebook since you will be reusing the same variables you previous created and used in labs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions\n",
    "\n",
    "So far we have worked on `EDA`. This lab will focus on data cleaning and wrangling from everything we noticed before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.ufunc size changed\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('we_fn_use_c_marketing_customer_value_analysis.csv')\n",
    "data.set_index('Customer', drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. We will start with removing outliers. So far, we have discussed different methods to remove outliers. Use the one you feel more comfortable with, define a function for that. Use the function to remove the outliers and apply it to the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers(df, threshold=1.5):\n",
    "    numerical = df.select_dtypes(np.number)\n",
    "    columns = numerical.columns\n",
    "    for column in columns:\n",
    "        if len(df[column].unique()) < 100:\n",
    "            continue\n",
    "        else:\n",
    "            upper = np.percentile(df[column], 75)\n",
    "            lower = np.percentile(df[column], 25)\n",
    "            iqr = upper - lower\n",
    "            upper_limit = upper + threshold * iqr\n",
    "            lower_limit = lower - threshold * iqr\n",
    "            df = df[(df[column] > lower_limit) & (df[column] < upper_limit)]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = remove_outliers(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Create a copy of the dataframe for the data wrangling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_copy = data.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Normalize the continuous variables. You can use any one method you want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_numericals(data, threshold=20):\n",
    "    num = data.select_dtypes(np.number)\n",
    "    cont_columns = []\n",
    "    disc_columns = []\n",
    "    for col in num.columns:\n",
    "        if len(num[col].unique()) > threshold:\n",
    "            cont_columns.append(col)\n",
    "        else:\n",
    "            disc_columns.append(col)\n",
    "    continuous_df = data.loc[:, cont_columns]\n",
    "    discrete_df = data.loc[:, disc_columns]\n",
    "    return continuous_df, discrete_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous_data, discrete_data = split_numericals(data_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = StandardScaler().fit(continuous_data)\n",
    "x_standardized = transformer.transform(continuous_data)\n",
    "x_standardized = pd.DataFrame(x_standardized, columns=continuous_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Customer Lifetime Value</th>\n",
       "      <th>Income</th>\n",
       "      <th>Monthly Premium Auto</th>\n",
       "      <th>Months Since Last Claim</th>\n",
       "      <th>Months Since Policy Inception</th>\n",
       "      <th>Total Claim Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.065356</td>\n",
       "      <td>0.583423</td>\n",
       "      <td>-0.777085</td>\n",
       "      <td>1.697383</td>\n",
       "      <td>-1.542810</td>\n",
       "      <td>0.028144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.184071</td>\n",
       "      <td>0.335939</td>\n",
       "      <td>1.020067</td>\n",
       "      <td>0.299696</td>\n",
       "      <td>-0.358507</td>\n",
       "      <td>0.935451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.501708</td>\n",
       "      <td>-1.271769</td>\n",
       "      <td>0.927906</td>\n",
       "      <td>0.299696</td>\n",
       "      <td>0.610469</td>\n",
       "      <td>0.752698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.049252</td>\n",
       "      <td>0.173378</td>\n",
       "      <td>-0.592762</td>\n",
       "      <td>-0.299312</td>\n",
       "      <td>-0.143179</td>\n",
       "      <td>-1.203902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.697636</td>\n",
       "      <td>0.801930</td>\n",
       "      <td>-0.777085</td>\n",
       "      <td>-0.099642</td>\n",
       "      <td>1.651220</td>\n",
       "      <td>-1.097758</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Customer Lifetime Value    Income  Monthly Premium Auto  \\\n",
       "0                -1.065356  0.583423             -0.777085   \n",
       "1                 2.184071  0.335939              1.020067   \n",
       "2                 0.501708 -1.271769              0.927906   \n",
       "3                -1.049252  0.173378             -0.592762   \n",
       "4                 0.697636  0.801930             -0.777085   \n",
       "\n",
       "   Months Since Last Claim  Months Since Policy Inception  Total Claim Amount  \n",
       "0                 1.697383                      -1.542810            0.028144  \n",
       "1                 0.299696                      -0.358507            0.935451  \n",
       "2                 0.299696                       0.610469            0.752698  \n",
       "3                -0.299312                      -0.143179           -1.203902  \n",
       "4                -0.099642                       1.651220           -1.097758  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_standardized.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. The time variable can be useful. Try to transform its data into a useful one. Hint: Day week and month as integers might be useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Effective To Date'] = pd.to_datetime(data['Effective To Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Month'] = data['Effective To Date'].dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Day Of Week'] = data['Effective To Date'].dt.dayofweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop('Effective To Date', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Since the model will only accept numerical data, check and make sure that every column is numerical, if some are not, change it using encoding.\n",
    "\n",
    "**Hint for Categorical Variables**\n",
    "\n",
    "- You should deal with the categorical variables as shown below (for ordinal encoding, dummy code has been provided as well):\n",
    "\n",
    "```\n",
    "# One hot to state\n",
    "# Ordinal to coverage\n",
    "# Ordinal to employmentstatus\n",
    "# Ordinal to location code\n",
    "# One hot to marital status\n",
    "# One hot to policy type\n",
    "# One hot to policy\n",
    "# One hot to renew offercustomer_df\n",
    "# One hot to sales channel\n",
    "# One hot vehicle class\n",
    "# Ordinal vehicle size\n",
    "\n",
    "data[\"coverage\"] = data[\"coverage\"].map({\"Basic\" : 0, \"Extended\" : 1, \"Premium\" : 2})\n",
    "# given that column \"coverage\" in the dataframe \"data\" has three categories:\n",
    "# \"basic\", \"extended\", and \"premium\" and values are to be represented in the same order.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basic       4923\n",
      "Extended    2313\n",
      "Premium      553\n",
      "Name: Coverage, dtype: int64\n",
      "Employed         4957\n",
      "Unemployed       1859\n",
      "Medical Leave     373\n",
      "Disabled          349\n",
      "Retired           251\n",
      "Name: EmploymentStatus, dtype: int64\n",
      "Suburban    4804\n",
      "Rural       1574\n",
      "Urban       1411\n",
      "Name: Location Code, dtype: int64\n",
      "Medsize    5484\n",
      "Small      1492\n",
      "Large       813\n",
      "Name: Vehicle Size, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Encode ordinal columns\n",
    "ordinal_cols = ['Coverage', 'EmploymentStatus', 'Location Code', 'Vehicle Size']\n",
    "ordinal = data_copy.loc[:, ordinal_cols]\n",
    "\n",
    "for col in ordinal_cols:\n",
    "    print(data[col].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Coverage\"] = data[\"Coverage\"].map({\"Basic\" : 0, \"Extended\" : 1, \"Premium\" : 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Vehicle Size\"] = data[\"Vehicle Size\"].map({\"Small\" : 0, \"Medsize\" : 1, \"Large\" : 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Location Code\"] = data[\"Location Code\"].map({\"Urban\" : 0, \"Suburban\" : 1, \"Rural\" : 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"EmploymentStatus\"] = data[\"EmploymentStatus\"].map({\"Urban\" : 0, \"Suburban\" : 1, \"Rural\" : 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine categorical & discrete numerical data\n",
    "categoricals = data_copy.select_dtypes(object)\n",
    "total_categoricals = pd.concat([categoricals, discrete_data], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_encoded = pd.get_dummies(total_categoricals, columns=total_categoricals.columns, \\\n",
    "    drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data for next lab\n",
    "data.to_csv('clean_data.csv')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
